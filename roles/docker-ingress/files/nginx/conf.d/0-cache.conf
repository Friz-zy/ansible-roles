# https://nginx.org/en/docs/http/ngx_http_fastcgi_module.html
# https://nginx.org/en/docs/http/ngx_http_proxy_module.html
# https://nginx.org/en/docs/http/ngx_http_uwsgi_module.html
# https://www.nginx.com/blog/nginx-caching-guide/
# https://docs.nginx.com/nginx/admin-guide/content-cache/content-caching/
# https://www.thedotproduct.org/posts/nginx-vary-header-handling.html
# https://trac.nginx.org/nginx/ticket/1840

# add_header X-Cache-Status $upstream_cache_status always;

# FASTCGI
fastcgi_cache_methods GET HEAD;
fastcgi_cache_min_uses 1;
fastcgi_cache_path /tmp/nginx-fastcgi-cache levels=1:2 keys_zone=FASTCGICACHE:20m inactive=12h max_size=1g use_temp_path=off;
fastcgi_cache_key "$request_method$scheme$host$request_uri"; # you can also add your cookie's name into cache key like $cookie_jessionid
fastcgi_cache_use_stale error timeout invalid_header http_500 http_503;
fastcgi_cache_revalidate on;

fastcgi_cache_bypass $cookie_nocache $arg_nocache$arg_comment;
fastcgi_no_cache $http_pragma $http_authorization;

# you can enable it here for global caching
# but I prefer configuring it in location blocks
# fastcgi_cache FASTCGICACHE;
# fastcgi_cache_valid 499 500 502 503 504 521 522 523 524 3s; # circuit breaker
# fastcgi_cache_valid 404 15m; # cache Not Found for decrease loading to backend
# fastcgi_cache_valid 301 308 1h; # cache Permanent Redirect for decrease loading to backend
# fastcgi_cache_valid 302 307 5s; # cache Temporary Redirect for decrease loading to backend
# fastcgi_cache_valid 200 0; # don't cache 200 and ANY by default
# fastcgi_cache_valid any 0; # see https://github.com/Friz-zy/nginx-common-configuration/blob/master/README.md

# if you for some reasons want to use stale (expired) cache
# you can enable this and add 'updating' into fastcgi_cache_use_stale
# when you use cache for any or 200 status requests
fastcgi_cache_background_update off;

# enable for limiting requests to backend
# if you use cache for any or 200 status requests
fastcgi_cache_lock off;
fastcgi_cache_lock_age 5s;
fastcgi_cache_lock_timeout 5s;

# PROXY
proxy_cache_methods GET HEAD;
proxy_cache_min_uses 1;
proxy_cache_path /tmp/nginx-proxy-cache levels=1:2 keys_zone=PROXYCACHE:20m inactive=12h max_size=1g use_temp_path=off;
proxy_cache_key "$request_method$scheme$host$request_uri"; # you can also add your cookie's name into cache key like $cookie_jessionid
proxy_cache_use_stale error timeout invalid_header http_500 http_503;
proxy_cache_revalidate on;

proxy_cache_bypass $cookie_nocache $arg_nocache$arg_comment;
proxy_no_cache $http_pragma $http_authorization;

# you can enable it here for global caching
# but I prefer configuring it in location blocks
# proxy_cache PROXYCACHE;
# proxy_cache_valid 499 500 502 503 504 521 522 523 524 3s; # circuit breaker
# proxy_cache_valid 404 15m; # cache Not Found for decrease loading to backend
# proxy_cache_valid 301 308 1h; # cache Permanent Redirect for decrease loading to backend
# proxy_cache_valid 302 307 5s; # cache Temporary Redirect for decrease loading to backend
# proxy_cache_valid 200 0; # don't cache 200 and ANY by default
# proxy_cache_valid any 0; # see https://github.com/Friz-zy/nginx-common-configuration/blob/master/README.md

# if you for some reasons want to use stale (expired) cache
# you can enable this and add 'updating' into proxy_cache_use_stale
# when you use cache for any or 200 status requests
proxy_cache_background_update off;

# enable for limiting requests to backend
# if you use cache for any or 200 status requests
proxy_cache_lock off;
proxy_cache_lock_age 5s;
proxy_cache_lock_timeout 5s;

# UWSGI
uwsgi_cache_methods GET HEAD;
uwsgi_cache_min_uses 1;
uwsgi_cache_path /tmp/nginx-uwsgi-cache levels=1:2 keys_zone=UWSGICACHE:20m inactive=12h max_size=1g use_temp_path=off;
uwsgi_cache_key "$request_method$scheme$host$request_uri"; # you can also add your cookie's name into cache key like $cookie_jessionid
uwsgi_cache_use_stale error timeout invalid_header http_500 http_503;
uwsgi_cache_revalidate on;

uwsgi_cache_bypass $cookie_nocache $arg_nocache$arg_comment;
uwsgi_no_cache $http_pragma $http_authorization;

# you can enable it here for global caching
# but I prefer configuring it in location blocks
# uwsgi_cache UWSGICACHE;
# uwsgi_cache_valid 499 500 502 503 504 521 522 523 524 3s; # circuit breaker
# uwsgi_cache_valid 404 15m; # cache Not Found for decrease loading to backend
# uwsgi_cache_valid 301 308 1h; # cache Permanent Redirect for decrease loading to backend
# uwsgi_cache_valid 302 307 5s; # cache Temporary Redirect for decrease loading to backend
# uwsgi_cache_valid 200 0; # don't cache 200 and ANY by default
# uwsgi_cache_valid any 0; # see https://github.com/Friz-zy/nginx-common-configuration/blob/master/README.md

# if you for some reasons want to use stale (expired) cache
# you can enable this and add 'updating' into uwsgi_cache_use_stale
# when you use cache for any or 200 status requests
uwsgi_cache_background_update off;

# enable for limiting requests to backend
# if you use cache for any or 200 status requests
uwsgi_cache_lock off;
uwsgi_cache_lock_age 5s;
uwsgi_cache_lock_timeout 5s;


# enable if you use NGINX PLUS

# geo $purge_allowed {
#   127.0.0.0/8     1;  # allow from localhost
#   ::1/128         1;  # allow from localhost
#   10.0.0.0/8      1;  # allow from private network
#   100.64.0.0/10   1;  # allow from private network
#   172.16.0.0/12   1;  # allow from private network
#   192.168.0.0/16  1;  # allow from private network
#   fc00::/7        1;  # allow from private network
#   default         0;  # deny from other
# }

# map $request_method $purge_method {
#   PURGE   $purge_allowed;
#   default 0;
# }

# fastcgi_cache_purge $purge_method;
# proxy_cache_purge $purge_method;
# uwsgi_cache_purge $purge_method;
